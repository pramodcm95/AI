{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Pramod Mahajan Chikkaballekere Manjunatha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # The code to download the mnist data original came from\n",
    "    # https://cntk.ai/pythondocs/CNTK_103A_MNIST_DataLoader.html\n",
    "    \n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import struct\n",
    "\n",
    "    try: \n",
    "        from urllib.request import urlretrieve \n",
    "    except ImportError: \n",
    "        from urllib import urlretrieve\n",
    "\n",
    "    def load_data(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x3080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if n != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} entries.\".format(num_samples)\n",
    "                    )\n",
    "                crow = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                ccol = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if crow != 28 or ccol != 28:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected 28 rows/cols per image.\"\n",
    "                    )\n",
    "                # Read data.\n",
    "                res = np.frombuffer(\n",
    "                    gz.read(num_samples * crow * ccol), dtype=np.uint8\n",
    "                )\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples, crow, ccol)) / 256\n",
    "\n",
    "\n",
    "    def load_labels(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x1080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))\n",
    "                if n[0] != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} rows.\".format(num_samples)\n",
    "                    )\n",
    "                # Read labels.\n",
    "                res = np.frombuffer(gz.read(num_samples), dtype=np.uint8)\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples))\n",
    "\n",
    "\n",
    "    def try_download(data_source, label_source, num_samples):\n",
    "        data = load_data(data_source, num_samples)\n",
    "        labels = load_labels(label_source, num_samples)\n",
    "        return data, labels\n",
    "    \n",
    "    \n",
    "    # Not sure why, but yann lecun's website does no longer support \n",
    "    # simple downloader. (e.g. urlretrieve and wget fail, while curl work)\n",
    "    # Since not everyone has linux, use a mirror from uni server.\n",
    "    #     server = 'http://yann.lecun.com/exdb/mnist'\n",
    "    server = 'https://raw.githubusercontent.com/fgnt/mnist/master'\n",
    "    \n",
    "    # URLs for the train image and label data\n",
    "    url_train_image = f'{server}/train-images-idx3-ubyte.gz'\n",
    "    url_train_labels = f'{server}/train-labels-idx1-ubyte.gz'\n",
    "    num_train_samples = 60000\n",
    "\n",
    "    print(\"Downloading train data\")\n",
    "    train_features, train_labels = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "    # URLs for the test image and label data\n",
    "    url_test_image = f'{server}/t10k-images-idx3-ubyte.gz'\n",
    "    url_test_labels = f'{server}/t10k-labels-idx1-ubyte.gz'\n",
    "    num_test_samples = 10000\n",
    "\n",
    "    print(\"Downloading test data\")\n",
    "    test_features, test_labels = try_download(url_test_image, url_test_labels, num_test_samples)\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-labels-idx1-ubyte.gz\n",
      "Done.\n",
      "Downloading test data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-labels-idx1-ubyte.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_labels = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = train_features.reshape(-1, 28*28)\n",
    "test_images = test_features.reshape(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, value, operation):\n",
    "        self.value = np.array(value)\n",
    "        self.operation = operation\n",
    "    \n",
    "class Parameter(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used for Variables that are learnable.\n",
    "    You can later use this class to distinguish learnable variables\n",
    "    from other variables (`isinstance(variable, Parameter)`).\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)\n",
    "        self.gradient = np.zeros_like(self.value)\n",
    "        \n",
    "class Input(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used as wrapper for inputs that are not learnable.\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.parameters = []\n",
    "    \n",
    "    def apply(self, X):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def grad(self,D):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def add_param(self, values):\n",
    "        param = Parameter(values)\n",
    "        self.parameters.append(param)\n",
    "        return param\n",
    "    \n",
    "    def update_parameters(self, optimizer):\n",
    "        for param in self.parameters:\n",
    "            optimizer.update(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential(Layer):\n",
    "    def __init__(self, *layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for layer in layers:\n",
    "            self.parameters.extend(layer.parameters) \n",
    "        \n",
    "    def apply(self, X):\n",
    "        backprops = []\n",
    "        oper = X\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            oper, backprop = layer.apply(oper)\n",
    "            backprops.append(backprop)\n",
    "\n",
    "        def grad(D):\n",
    "            for backprop in reversed(backprops):\n",
    "                D = backprop(D)\n",
    "            return D\n",
    "        \n",
    "        return oper , grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineLayer(Layer):\n",
    "    def __init__(self, in_units, out_units):\n",
    "        super().__init__()\n",
    "        least = 0.01\n",
    "        w_values = np.random.uniform(size=[in_units, out_units],\n",
    "                    low=-least,\n",
    "                    high=least\n",
    "                    )\n",
    "        self.W = self.add_param(w_values)\n",
    "        self.b = self.add_param(np.zeros(shape=out_units))\n",
    "        \n",
    "    def apply(self, X):\n",
    "        \n",
    "        def grad(D):\n",
    "            self.W.gradient = np.einsum('ji,jk->ik',X,D)\n",
    "            self.b.gradient = np.sum(D,axis=0)\n",
    "            bck_val = np.einsum('ij,kj->ik',D,self.W.value)\n",
    "            return bck_val\n",
    "        \n",
    "        frd_val = np.einsum('ij,jk->ik',X,self.W.value) + self.b.value # adding bias\n",
    "       \n",
    "       \n",
    "        return frd_val, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Relu activation layer\n",
    "class ReLU(Layer):\n",
    "    def apply(self, X):\n",
    "        z = np.maximum(X, 0)  \n",
    "        \n",
    "        def grad(D):\n",
    "            gx = D.copy()\n",
    "            \n",
    "            # Modify `gx` such that the gradient is corrected for x < 0.\n",
    "            gx[X < 0] = 0 \n",
    "            return gx\n",
    "\n",
    "        return z , grad\n",
    "    \n",
    "# define sigmoid activation layer    \n",
    "class Sigmoid(Layer):\n",
    "    def apply(self, X):\n",
    "        oper = 1/(1+np.exp(-X))\n",
    "        \n",
    "        def gradient(D):\n",
    "            return D \n",
    "        \n",
    "        return oper, gradient\n",
    "    \n",
    "# define optimizer as SGD\n",
    "class SGD():\n",
    "    def __init__(self, lr=0.001):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, param):\n",
    "        param.value = param.value - self.lr * param.gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross entropy loss\n",
    "def cross_entropy(predictions, targets, epsilon=1e-11):\n",
    "    ce = -(np.sum(targets*np.log(predictions)))   # sum(p * logpi)\n",
    "    error = predictions - targets  \n",
    "    return ce , error  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot to specify mulitclass classification    \n",
    "def one_hot_encoder(train_labels):\n",
    "    r = train_labels.shape[0]\n",
    "    one_hot = np.zeros((r, 10))\n",
    "    for i in range(r):\n",
    "        one_hot[i][train_labels[i]] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST():\n",
    "    def __init__(self, model, loss_function, optimizer):\n",
    "        self.model = model\n",
    "        self.loss = loss_function\n",
    "        self.optimizer = optimizer\n",
    "      \n",
    "    # batch_size per update(specified later in training)\n",
    "    def train_as_batch(self,X_train,Y_train):\n",
    "        Y_train_, gradient = self.model.apply(X_train)\n",
    "        Loss , D = self.loss(Y_train_, Y_train)          \n",
    "        gradient(D)\n",
    "        self.model.update_parameters(self.optimizer)\n",
    "        return Loss\n",
    "  \n",
    "    def train(self, X_train, Y_train, batch_size , epochs):\n",
    "        loss = []    # empty array to append loss values, which can be plotted later for better visualization\n",
    "        for epoch in range(epochs):\n",
    "            p = np.random.permutation(len(X_train))\n",
    "            L_coll = 0\n",
    "            for val in range(0, len(X_train), batch_size):\n",
    "                X_batch = X_train[p[val:val + batch_size]]\n",
    "                Y_batch = Y_train[p[val:val + batch_size]]\n",
    "                L_coll += self.train_as_batch(X_batch, Y_batch)\n",
    "            loss.append(L_coll)\n",
    "        return loss\n",
    "    \n",
    "    # predicts accuracy of my model's prediction compared to actual output\n",
    "    def accuracy(y_pred, y_test):\n",
    "        correct_predictions = np.count_nonzero(y_pred==y_test)\n",
    "        acc = correct_predictions / (y_test.shape[0]/100)\n",
    "        print(\"The Model has achieved the accuracy of \" + str(acc) + \"% on test dataset.\")\n",
    "        return acc\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        ypred, nothing = self.model.apply(X_test)\n",
    "        return ypred.argmax(axis=-1)\n",
    "    \n",
    "    def dump_parameters(self,file):\n",
    "        with open(file, 'w') as fp:\n",
    "            json.dump([p.value.tolist() for p in self.model.parameters],fp)\n",
    "            print('Wrote the parameters')\n",
    "            \n",
    "    def load_parameters(self, file):\n",
    "        with open(file) as fp:\n",
    "            parameters_values = json.load(fp)\n",
    "        for p, p_value in zip(self.model.parameters, parameters_values):\n",
    "            p.value[...] = p_value\n",
    "        print('Loaded the parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model with 1 input layer, 1 hidden layer with 500 neurons, output layer of 10 neurons, one for each of 10 digits\n",
    "neurons_in_layer = 500\n",
    "lr = 0.008   # Learning rate\n",
    "epochs = 35\n",
    "batch_size = 32\n",
    "\n",
    "X_train = training_images\n",
    "\n",
    "y_train = train_labels\n",
    "Y_train = one_hot_encoder(train_labels) \n",
    "\n",
    "X_test = test_images\n",
    "Y_test = test_labels\n",
    "\n",
    "model = MNIST(Sequential(AffineLayer(784, neurons_in_layer), ReLU(), AffineLayer(neurons_in_layer, Y_train.shape[1]),Sigmoid()), \n",
    "    loss_function = cross_entropy, optimizer = SGD(lr=lr))\n",
    "\n",
    "losses = model.train(X_train, Y_train, batch_size=batch_size, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote the parameters\n"
     ]
    }
   ],
   "source": [
    "# save weights to a json file\n",
    "model.dump_parameters(\"wt_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new empty model here to load weights\n",
    "hidden_neurons = 500\n",
    "lr = 0.008\n",
    "\n",
    "val_model = MNIST(\n",
    "    Sequential(\n",
    "        AffineLayer(784, hidden_neurons), ReLU(), \n",
    "        AffineLayer(hidden_neurons, 10),Sigmoid()), \n",
    "    loss_function = cross_entropy, \n",
    "    optimizer = SGD(lr=lr)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the parameters\n"
     ]
    }
   ],
   "source": [
    "# load weights from a saved json file in a new model\n",
    "val_model.load_parameters(\"wt_final.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model has achieved the accuracy of 98.57% on test dataset.\n"
     ]
    }
   ],
   "source": [
    "# use the new empty model with weights loaded from json to make prediction\n",
    "val_model_accuracy = MNIST.accuracy(val_model.predict(X_test), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model has achieved the accuracy of 98.57% on test dataset.\n"
     ]
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "# acuuracy prediction\n",
    "y_pred = model.predict(X_test)\n",
    "acc = MNIST.accuracy(y_pred, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
